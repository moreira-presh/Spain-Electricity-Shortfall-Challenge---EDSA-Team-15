# -*- coding: utf-8 -*-
"""TEAM 15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cu0jUGVJmjcZkQX2VvCoVwagcGTSJsaR

# Regression Predict Student Solution

© Explore Data Science Academy

---
### Honour Code

I {**Team 15**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).

Non-compliance with the honour code constitutes a material breach of contract.

### Predict Overview: Spain Electricity Shortfall Challenge

The government of Spain is considering an expansion of it's renewable energy resource infrastructure investments. As such, they require information on the trends and patterns of the countries renewable sources and fossil fuel energy generation. Your company has been awarded the contract to:

- 1. analyse the supplied data;
- 2. identify potential errors in the data and clean the existing data set;
- 3. determine if additional features can be added to enrich the data set;
- 4. build a model that is capable of forecasting the three hourly demand shortfalls;
- 5. evaluate the accuracy of the best machine learning model;
- 6. determine what features were most important in the model’s prediction decision, and
- 7. explain the inner working of the model to a non-technical audience.

Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:

> In this project you are tasked to model the shortfall between the energy generated by means of fossil fuels and various renewable sources - for the country of Spain. The daily shortfall, which will be referred to as the target variable, will be modelled as a function of various city-specific weather features such as `pressure`, `wind speed`, `humidity`, etc. As with all data science projects, the provided features are rarely adequate predictors of the target variable. As such, you are required to perform feature engineering to ensure that you will be able to accurately model Spain's three hourly shortfalls.
 
On top of this, she has provided you with a starter notebook containing vague explanations of what the main outcomes are.

<a id="cont"></a>

## Table of Contents

<a href=#one>1. Importing Packages</a>

<a href=#two>2. Loading Data</a>

<a href=#three>3. Exploratory Data Analysis (EDA)</a>

<a href=#four>4. Data Engineering</a>

<a href=#five>5. Modeling</a>

<a href=#six>6. Model Performance</a>

<a href=#seven>7. Model Explanations</a>

## Problem statement

* To prevent climate change and ensure sustainability, the world is moving toward the usage of renewable energy resources. Renewable energy sources will also ensure a steady supply of energy. As a result, new markets, enterprises, and job opportunities will emerge, providing greater options for individuals to earn a living and elevate themselves, their families, and their communities out of poverty. Businesses and the economy as a whole suffer from a lack of reliable power supply.

* Renewable energy sources accounted for 43% of all electricity produced in Spain in the year 2020. As a result, the government is considering increasing infrastructure spending. However, they will need information on the country's renewable resource and fossil fuel energy generating trends and patterns in order to do so..

* As aspiring data scientists, we were charged with creating a model that would help estimate the three-hourly load shortfall in Spain precisely. This information will aid the government in determining how much infrastructure spending should be increased.

## Objectives

* Explore and visualize the dataset.
* Clean and engineer the dataset.
* Build several models that will predict the 3 hourly load shortfall.
* Assess the accuracy of the models.
* Choose the best model to make predictions.

## Features

1. Time: Weather conditions in each city at a particular date and time
2. Wind_speed: Wind speed in each city
3. Wind_deg: The direction of the wind in each city
4. Pressure: Atmospheric pressure in each city
5. Rain: The amount of rain in each city in 1 hour or 3 hours
6. Snow: The amount of snowfall in each city
7. Cloud_all: Percentage cloud coverage in each city

<a id="one"></a>
## 1. Importing Packages
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Importing Packages ⚡ |
| :--------------------------- |
| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |

---

## We start first by importing the necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# Libraries for data loading, data manipulation and data visulisation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px
from statsmodels.graphics.correlation import plot_corr

# Libraries for data preparation and model building
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics 
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.metrics import mean_squared_error as MSE
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
import math
from statsmodels.graphics.correlation import plot_corr
import statsmodels.formula.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
# Setting global constants to ensure notebook results are reproducible
#PARAMETER_CONSTANT = ###

"""<a id="two"></a>
## 2. Loading the Data
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Loading the data ⚡ |
| :--------------------------- |
| In this section you are required to load the data from the `df_train` file into a DataFrame. |

---

### Loading and displaying an overview of the data
"""

train_data = pd.read_csv('df_train.csv') # load the train data
test_data = pd.read_csv('df_test.csv')  # load the test data

#overview dataset
print(f' There are {train_data.shape[0]} rows and {train_data.shape[1]} columns')
train_data.head(3)

"""<a id="three"></a>
## 3. Exploratory Data Analysis (EDA)
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Exploratory data analysis ⚡ |
| :--------------------------- |
| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |

---

"""

#Read data
train_data.head(3)

"""Looking at our data, we observe that because of the shape of the data, it is not possbile to view hidden columns, thus we cannot determine hidden features, in this case we will use the transpose method"""

#Read the train data in Transpose
"""
The addition of the *T* (transpose)tranforms our data by changing the diagonals of the columns and index """
train_data.head(10).T

#checking the shape of the data
train_data.shape

"""Observations:¶

  1. There are 49 columns and 8763 rows.
  2. We have an unnamed column having the same index value as seen above, this column is insignificant to our use case
  3. Valencia_wind_deg and Seville_pressure columns show category values, this is a regression (numeric) data, thus requires us to convert to numerical values




"""

"""
The common distinct data types seen here are of floats and object form.
Also, the result shows the presence of missing values in Valencia_pressure
"""
print(train_data.info()) #checking the data type of each column in the data
print('\n')
print(train_data.isnull().sum()) #checking for possible missing values

"""* It can be deduced that Valencia_pressure has less than 8763 non-null indicating that it has missing values.
* We hope to fill up these missing values using either mean or median in the featutre engineering section of the notbook.

* The datatype 'object' indicates that the columns time, Valencia wind deg, and Seville pressure are non-numeric.

#### Performing a Descriptive Statistics of Features
"""

# look at data statistics
train_data.describe().T

"""Looking at our data, we can infer the following:
   - We can tell from the **Mean(average)** that some of the columns such as Barcelona Pressure, Bilbao Pressure, Valencia Pressure etc. show very large values which is far from the range. 
   - This is evident also in their maximum values which would infer the presence of outliers.
   

We would have to confirm this in our next analysis

### Checking Skewness/Kurtosis and Outliers

- Skewness is simply the measure of symmetry or more precisely, the lack of symmetry.

- Kurtosis is the measure of how heavy its tails are compared to a normal distribution
"""

train_data.kurtosis().plot()

#Checking for outliers in the different columns
train_data.kurtosis()

"""* Below are features with large numbers of outliers as shown by **kurtosis > 3**; 
Bilbao_rain_1h, Valencia_wind_speed, Barcelona_rain_1h, Seville_rain_1h, Bilbao_snow_3h, Barcelona_pressure, Seville_rain_3h, Valencia_snow_3h, Barcelona_rain_3h, Madrid_weather_id, Barcelona_weather_id and Seville_weather_id.
* The outliers observed in Barcelona_pressure are definitely due to some sort of error, as a pressure of 3687.564230 is too high. The maximum pressure recorded in history is 1084, and the maximum pressure for the other cities in the dataset are also below this value.
* This value can be replaced or dropped during data engineering.
* Valencia_wind_speed has a maximum of 52, there is also something wrong with that value. The highest wind speed recorded in history is 20.This value should also be replaced or dropped.
* The outliers in the other features can maybe be attributed to a significant change in weather conditions on the day that the data was collected and hence we can leave them.

### Let's visualize the features with obvious outliers.
"""

sns.boxplot(train_data['Barcelona_pressure'])

"""* The boxplot shows that Barcelona_pressure has about seven outliers

* We then looked at values that are greater than the maximum pressure ever recorded (1084).
"""

#Visualizing the Valencia_wind_speed data
sns.boxplot(x='Valencia_wind_speed', data=train_data)

"""* We can see that there is a significant number of outliers in this feature

### Checking for Skewness
"""

#Checking for outliers in the different columns
plt.figure(figsize = [10,5])
train_data.skew(axis=0, skipna=True).plot()

train_data.skew()

"""* The following features have high positive symmetrical data; Bilbao_snow_3h, Barcelona_pressure, Seville_rain_3h, Barcelona_rain_3h and Valencia_snow_3h.
* Madrid_weather_id, Barcelona_weather_id and Seville_weather_id have data with high negative symmetry.
* It is also noted that this features are also identified as outliers.

### An Overview of our Target Variable with Time
"""

#Ploting time against Load_shortfall_3h to see relationship
fig = px.line(train_data, y = train_data['load_shortfall_3h'], x =train_data['time'], width =900, height=400 )
fig.show()

"""We can tell from the image the seasonality in the time axis on their load_shortfall_3h values, We will need to desample (break them into bits) this image to get a better understanding of the graph

To do this we will have to desample the time into:

  * Year
  * Months
  * Weeks
  * Days
  * Hours


"""

train_data.groupby([train_data['time'].astype('datetime64').dt.hour])['load_shortfall_3h'].sum().plot(legend = True)

"""Write something here"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.year])['load_shortfall_3h'].mean(),
        title = 'Load_shortfall_3h grouped by Year',
        y='load_shortfall_3h',width =800, height=400 )

"""The yearly Load_short_fall plots indicates an increase in load short fall from 2016 down to 2017 surpassing the previous years

"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.month])['load_shortfall_3h'].mean(),
        title = 'Load_shortfall_3h grouped by Month of Year',
        y='load_shortfall_3h', width =800, height=400)

"""Also the plot above, indicates a higher 'load short fall' from middle of June down to December """

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.weekofyear])['load_shortfall_3h'].mean(), 
        title = 'Load_shortfall_3h grouped by Week of the Year', y='load_shortfall_3h', width =700, height=400)

"""No much information can be deduced from the the week of the year Load_short_fall as shown above"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.dayofyear])['load_shortfall_3h'].mean(), 
        title = 'Load_shortfall_3h grouped by Day of the Year', y='load_shortfall_3h', width =700, height=400)

"""The minimum load_short_fall_3h recorded is 1,862k while the maximum is 17,306k as seen from the Day of the year plots

"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.day])['load_shortfall_3h'].mean(), 
        title = 'Load_shortfall_3h grouped by Day of the Month', y='load_shortfall_3h', width =800, height=400 )

"""The plots above shows 10k to 12k consistent recorded values from middle of each to the end of the month"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.dayofweek])['load_shortfall_3h'].mean(), 
        title = 'Load_shortfall_3h grouped by Day of the Week', y='load_shortfall_3h', width =800, height=400 )

"""There seems to be a decrease in the Load_short_fall_3h Day of the week plots on Fridays and Saturdays, we can not account for the reasons"""

px.line(train_data.groupby([train_data['time'].astype('datetime64').dt.hour])['load_shortfall_3h'].mean(), 
        title = 'Load_shortfall_3h grouped by Hour of Day', y='load_shortfall_3h', width =800, height=400 )

"""There seems to be an increase in the Load_short_fall_3h hourly plots each day, mostly from 10hours and above

### Let us check the Distribution of our Data
"""

plt.hist(train_data['load_shortfall_3h'])

"""### Let's have a look at the correlation between the numeric variables."""

# Visualizing the correlation
fig = plt.figure(figsize=(10,8));
ax = fig.add_subplot(111);
plot_corr(train_data.corr(), xnames = train_data.corr().columns, ax = ax, );

"""* First, we can easily tell the presence of high correlation (in red) between features on the heatmap at the bottom right corner of our graph
* A breakdown of handling such occurence will be discussed in the feature engineering section of the notebook
* It is important to consider this step when choosing the best features which in turn would result to an improvement of our model.

<a id="four"></a>
## 4. Data Engineering
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Data engineering ⚡ |
| :--------------------------- |
| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |

---

We will be carrying out Feature Engineering in this section of our notebook. 

We have highlighted some key points to consider - 
   * Why should we use Feature Engineering in data science?
   * Feature Selection/Importance
   * Handling missing values
   * Handling outliers
   * Feature Scaling

### Why should we use Feature Engineering in data science?
In Data Science, the performance of the model is dependent on data preprocessing and data handling. Suppose if we build a model without Handling data, we got an accuracy of around 70%. By applying the Feature engineering on the same model there is a chance to increase the performance from 70% to more.

Simply, by using Feature Engineering we improve the performance of the model.

CONT'D -- As we saw in the previous section (EDA), we highlighted some columns to be dropped as well as columns with categorical values.

We will now do the following:
    
   - Drop the Unnammed Column
   - Connvert both Seville_pressure and Valencia_wind_degree columns from categorical to numerical values.

Also, we will be converting or downsampling the **Time** column to various date/time format viz;
  
   - Year
   - Month of the Year
   - Week of the Year
   - Day of the Year
   - Day of the Month
   - Day of the Week
   - Hour of the Week
   - Hour of the Day
   
   
This will enable us have a better and larger expression of our data during modeling
"""

#Filling missing values
train_data['Valencia_pressure'].fillna(train_data['Valencia_pressure'].mean(), inplace = True)

"""First we will start by Transforming the Valencia_wind_deg and Seville_pressure columns to numeric.
This is done to ensure uniformity (numeric values) in our model"""

train_data['Valencia_wind_deg'] = train_data['Valencia_wind_deg'].str.extract('(\d+)').astype('int64')
train_data['Seville_pressure'] = train_data['Seville_pressure'].str.extract('(\d+)').astype('int64')

"""The next step is to engineer new features from the time column"""

#Engineering New Features ( i.e Desampling the Time) that will help us in our modeling

"""
We had to convert the time type from an object to a datetime format using the 'astype' method before desampling

"""
train_data['Year']  = train_data['time'].astype('datetime64').dt.year
train_data['Month_of_year']  = train_data['time'].astype('datetime64').dt.month
train_data['Week_of_year'] = train_data['time'].astype('datetime64').dt.weekofyear
train_data['Day_of_year']  = train_data['time'].astype('datetime64').dt.dayofyear
train_data['Day_of_month']  = train_data['time'].astype('datetime64').dt.day
train_data['Day_of_week'] = train_data['time'].astype('datetime64').dt.dayofweek
train_data['Hour_of_week'] = ((train_data['time'].astype('datetime64').dt.dayofweek) * 24 + 24) - (24 - train_data['time'].astype('datetime64').dt.hour)
train_data['Hour_of_day']  = train_data['time'].astype('datetime64').dt.hour

"""Let us have a look at the correlation(s) between our newly created temporal features"""

Time_df = train_data.iloc[:,[-8,-7,-6,-5,-4,-3,-2,-1]]
plt.figure(figsize=[10,6])
sns.heatmap(Time_df.corr(),annot=True )

"""Looking at our heatmap tells us that we have high Multicollinearity present in our new features.
The features involved are  - 

- Week of the year
- Day of the year
- Month of the year
- Day of the week
- Hour of the week

We would have to drop either one of the  features that have high correlation with each other

Alongside dropping these features mentioned above, we would also be dropping the time and Unnamed column
"""

train_data = train_data.drop(columns=['Week_of_year','Day_of_year','Hour_of_week', 'Unnamed: 0','time'])

"""### Feature Importance/Selection

Feature selection is the process where you automatically or manually select the features that contribute the most to your prediction variable or output. Selecting the important independent features which have more relation with the dependent feature will help to build a good model. There are some methods for feature selection:

**Feature importance** gives you a score for each feature of your data. The higher the score, the more important or relevant that feature is to your target feature.

Feature importance is an inbuilt class that comes with tree-based classifiers such as:

    Random Forest Classifiers
    Extra Tree Classifiers


##### Correlation Matrix with Heatmap

Heatmap is a graphical representation of 2D (two-dimensional) data. Each data value represented in a matrix.

First, we'll plot the pair plot between all independent features and dependent features. It will give the relation between dependent and independent features. The relation between the independent feature and the dependent feature is less than 0.2 then choose that independent feature for building a model.
"""

plt.figure(figsize=[35,15])
sns.heatmap(train_data.corr(),annot=True )

"""Just as we mentioned in our EDA, we noticed the presence of high correlations between the predictor columns and also possible outliers.

Here, we would have to drop these columns to improve the performance of our model and reduce any possibility of overfitting in our model


Before we drop these columns

### Filling Missing Values
To do this, we will fill in the missing values present in Valencia_pressure column using the **mean** method.

#### Let us chek if this approach corresponds with our feature selection.

Using SelectKBest and Chi2 to perform Feature Selection
"""

## Splitting our data into dependent Variable and Independent Variable
X = train_data.drop(columns = 'load_shortfall_3h')
y = train_data['load_shortfall_3h'].astype('int')

bestfeatures = SelectKBest(score_func=chi2, k=10)
fit = bestfeatures.fit(X,y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)
featureScores = pd.concat([dfcolumns, dfscores], axis=1)
featureScores.columns = ['Features', 'Score']
new_X = featureScores.sort_values('Score',ascending=False).head(40)
new_X.tail(10) #To get the least important feature based on ther score

"""This result backups our claim, were we saw in the  heatmap multicollinearity between features, and from our feature selection, we can see those features as having the lowest significance in our data.

### Dropping Outliers
We have one more thing to do, which is to remove possible outliers. Also, we will select the important features for our model thus dropping others having multicollinearity
"""

X = X[['Madrid_wind_speed', 'Valencia_wind_deg', 'Bilbao_rain_1h',
       'Valencia_wind_speed', 'Seville_humidity', 'Madrid_humidity',
       'Bilbao_clouds_all', 'Bilbao_wind_speed', 'Seville_clouds_all',
       'Bilbao_wind_deg', 'Barcelona_wind_speed', 'Barcelona_wind_deg',
       'Madrid_clouds_all', 'Seville_wind_speed', 'Barcelona_rain_1h',
       'Seville_pressure', 'Seville_rain_1h', 'Bilbao_snow_3h',
       'Barcelona_pressure', 'Seville_rain_3h', 'Madrid_rain_1h',
       'Barcelona_rain_3h', 'Valencia_snow_3h', 'Madrid_weather_id',
       'Barcelona_weather_id', 'Bilbao_pressure', 'Seville_weather_id',
       'Valencia_pressure', 'Seville_temp_max', 'Bilbao_weather_id', 
        'Valencia_humidity', 'Year', 'Month_of_year', 'Day_of_month', 'Day_of_week', 'Hour_of_day']]

plt.figure(figsize=[20,10])
sns.heatmap(X.corr(),annot=True )

"""We have been able to remove the collinearity seen in previous heatmaps and also selected specific features to train our model with

### Feature Scaling

Lastly, before we carry out modeling, it is important to scale our data. As we saw during the EDA, we noticed how some columns(features) had values that were out of range when we compared their mean, max and  standard deviation. This can result to bias in the model during decision making, thus it is important to convert all the column values to a certain range/scale.

#### What is Feature Scaling?
Feature scaling is the process of normalising the range of features in a dataset. Real-world datasets often contain features that are varying in degrees of magnitude, range and units. Therefore, in order for machine learning models to interpret these features on the same scale, we need to perform feature scaling.

In this project, we will be carrying out ***Standard Scaling***, becasue of it's **robustness** to outliers
"""

# Create standardization object
scaler = StandardScaler()

# Save standardized features into new variable
"""
We used a fit transform method, which first fits in the standardscaler and then transforms the data """
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled,columns=X.columns)
X_scaled.head()

y.head()

"""<a id="five"></a>
## 5. Modelling
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Modelling ⚡ |
| :--------------------------- |
| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |

---

### Model Building
1. We'll split the data into train and test, to be able to evaluate the model that we build on the train data.
3. Build a Linear Regression model which would serve as our base model using the train data.
4. Try and improve the linear model by employing Lasso and Ridge
5. Try out other models like decision trees, Random Forest and SVR
"""

#Separating our models into training set and testing set
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state = 42)

"""What we did here was to split our data into 80% for training and the remaining 20% for testing i.e *test_size = 0.2*

We made use of the *train_test_split* syntax from the **sklearn** library to carry out the splitting
"""

#checking the shape of the training and testing data

print('Training predictor:', X_train.shape)
print('Training target:', y_train.shape)
print('Testing predictor:', X_test.shape)
print('Testing target:', y_test.shape)

"""* We have been able to allocate 7010 features/observations to the training set of our data.
* We have also allocated the remainder i.e 1753 of observations to the testing set of our data.

**N/B:** These values are as a result of the splitting ratio carried out, it is important to note that any change in the splitting ration would affect the value and shape of the training and testing sets

### Multiple linear regression model 
As our basline, we would first make use of *Linear Model*.    
The term linear model implies that the model is specified as a linear combination of features. Based on training data, the learning process computes one weight for each feature to form a model that can predict or estimate the target value.
"""

#Instantiate the model
lm = LinearRegression()
#Fit the model into training set
lm.fit(X_train, y_train)

#predict on unseen data
predict = lm.predict(X_test)
train_predict = lm.predict(X_train) #predicting on the same training set

"""### Lasso Regression (L1 Norm)

Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values are shrunk towards a central point, like the mean. The lasso procedure encourages simple, sparse models (i.e. models with fewer parameters).

The lasso regression allows you to shrink or regularize these coefficients to avoid overfitting and make them work better on different datasets. This type of regression is used when the dataset shows high multicollinearity or when you want to automate variable elimination and feature selection
"""

# Create LASSO model object, setting alpha to 0.01
""" when alpha is 0, Lasso regression produces the same coefficients as a linear regression. When alpha is very very large, all coefficients are zero."""
lasso = Lasso(alpha=0.01)
# Train the LASSO model
lasso.fit(X_train, y_train)
# Get predictions
lasso_pred = lasso.predict(X_test)

"""### Ridge Regression (L2 Norm)
Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity
"""

# Creating Ridge model
Ridge = Ridge()
# Train the model
Ridge.fit(X_train, y_train)
# Get predictions
Ridge_pred = Ridge.predict(X_test)

"""### Support Vector Regressor

While linear regression models minimize the error between the actual and predicted values through the line of best fit, SVR manages to fit the best line within a threshold of values.

SVR uses the same basic idea as Support Vector Machine (SVM), a classification algorithm, but applies it to predict real values rather than a class.  
The aim is to fit as many instances as possible between the lines while limiting the margin violations
"""

# Instantiate support vector regression model
Sv_reg = SVR(kernel='rbf', gamma='auto')
# Train the model
Sv_reg.fit(X_train,y_train)
# Get predictions
SV_pred = Sv_reg.predict(X_test)

"""### Decision Tree Model
Decision tree regression observes features of an object and trains a model in the structure of a tree to predict data in the future to produce meaningful continuous output. Continuous output means that the output/result is not discrete, i.e., it is not represented just by a discrete, known set of numbers or values.
"""

# Instantiate regression tree model
Reg_tree = DecisionTreeRegressor(random_state=42)
# Fitting the model
Reg_tree.fit(X_train,y_train)
Tree_pred = Reg_tree.predict(X_test)

"""### Random Forest
Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model
"""

# Our forest consists of 200 trees with a max depth of 8 
RF = RandomForestRegressor(n_estimators=200, max_depth=8)
# Fitting the model
RF.fit(X_train,y_train)
RF_predict = RF.predict(X_test)



"""In this section of our notebook, we will evaluate the performance of **SIX  MODELS** we trained using metrics such as- 
 - Root Mean Squared Error (RMSE)
 - Mean Squared Error (MSE)
 - Mean Absolute Error (MAE)
 - Residual Sum of Squares Error (RSS) 

"""

#Comparing the True value and the Predicted Value of our models
Linear = pd.DataFrame({'Actual': y_test, 'Predicted': predict})
Lass_ = pd.DataFrame({'Actual': y_test, 'Predicted': lasso_pred})
Ridge_ = pd.DataFrame({'Actual': y_test, 'Predicted': Ridge_pred})
Sv_ = pd.DataFrame({'Actual': y_test, 'Predicted': SV_pred})
Des_ = pd.DataFrame({'Actual': y_test, 'Predicted': Tree_pred})
Rand_ = pd.DataFrame({'Actual': y_test, 'Predicted': RF_predict})

print(Linear.head()) #Linear Model 
print('\n')
print(Lass_.head()) # Lasso Model
print('\n')
print(Ridge_.head()) # Ridge Model
print('\n')
print(Sv_.head()) #SVR Model
print('\n')
print(Des_.head()) #Decision Tree Model
print('\n')
print(Rand_.head()) # Random Forest Model

"""From the Predicted values above, we can see some models have values very close to the actual label, let us not get carried away as it doesn't tell the whole story.

Some of these results might be attributed to overfitting and also exposed to a lot of noise/outliers.

We will therefore test our model's performance based on the Metrics aforementioned in the previous cell.

#### Comparing the Root Mean Square Error across Models
"""

Model_Performance = { 
    
                      'Test RMSE':
                    
                        {"Linear model": np.sqrt(metrics.mean_squared_error(y_test,predict)),
                        "Ridge": np.sqrt(metrics.mean_squared_error(y_test,Ridge_pred)),
                        "Lasso" : np.sqrt(metrics.mean_squared_error(y_test,lasso_pred)),
                         "SVR" : np.sqrt(metrics.mean_squared_error(y_test,SV_pred)),
                        "Decision Tree" : np.sqrt(metrics.mean_squared_error(y_test,Tree_pred)),
                        "Random Forest" : np.sqrt(metrics.mean_squared_error(y_test,RF_predict))}
                        
                    }

# create dataframe from dictionary
Model_Performance = pd.DataFrame(data=Model_Performance)
Model_Performance

px.bar(Model_Performance, y =Model_Performance['Test RMSE'],
       color = Model_Performance.index, width =700, height=400)

"""From the graph above, we can confirm that the Random Forest model performs better than others in terms of **RMSE**

### Comparing the Mean Square Error across Models
"""

Model_Performance2 = { 
    
                      'Test MSE':
                    
                        {"Linear model": (metrics.mean_squared_error(y_test,predict)),
                        "Ridge": (metrics.mean_squared_error(y_test,Ridge_pred)),
                        "Lasso" : (metrics.mean_squared_error(y_test,lasso_pred)),
                         "SVR" : (metrics.mean_squared_error(y_test,SV_pred)),
                        "Decision Tree" : (metrics.mean_squared_error(y_test,Tree_pred)),
                        "Random Forest" : (metrics.mean_squared_error(y_test,RF_predict))}
                        
                    }

# create dataframe from dictionary
Model_Performance2 = pd.DataFrame(data=Model_Performance2)
Model_Performance2

px.bar(Model_Performance2, y =Model_Performance2['Test MSE'],
       color = Model_Performance2.index, width =700, height=400)

"""From the graph above, we can confirm that the Random Forest model performs better than others in terms of **MSE**

### Comparing the Mean Absolute Error across Models
"""

Model_Performance3= { 
    
                      'Test MAE':
                    
                        {"Linear model": (metrics.mean_absolute_error(y_test,predict)),
                        "Ridge": (metrics.mean_absolute_error(y_test,Ridge_pred)),
                        "Lasso" : (metrics.mean_absolute_error(y_test,lasso_pred)),
                         "SVR" : (metrics.mean_absolute_error(y_test,SV_pred)),
                        "Decision Tree" : (metrics.mean_absolute_error(y_test,Tree_pred)),
                        "Random Forest" : (metrics.mean_absolute_error(y_test,RF_predict))}
                        
                    }

# create dataframe from dictionary
Model_Performance3 = pd.DataFrame(data=Model_Performance3)
Model_Performance3

px.bar(Model_Performance3, y =Model_Performance3['Test MAE'],
       color = Model_Performance3.index, width =700, height=400)

"""From the graph above, we can confirm that the Random Forest model performs better than others in terms of **MSE**

### Comparing the R-Squared across Models
"""

Model_Performance4= { 
    
                      'Test R^2':
                    
                        {"Linear model": (metrics.r2_score(y_test,predict)),
                        "Ridge": (metrics.r2_score(y_test,Ridge_pred)),
                        "Lasso" : (metrics.r2_score(y_test,lasso_pred)),
                         "SVR" : (metrics.r2_score(y_test,SV_pred)),
                        "Decision Tree" : (metrics.r2_score(y_test,Tree_pred)),
                        "Random Forest" : (metrics.r2_score(y_test,RF_predict))}
                        
                    }

# create dataframe from dictionary
Model_Performance4 = pd.DataFrame(data=Model_Performance4)
Model_Performance4

px.bar(Model_Performance4, y =Model_Performance4['Test R^2'],
       color = Model_Performance4.index, width =700, height=400)

"""From the graph above, we can confirm that the Random Forest model performs better than others in terms of R^2

From all of these Results, we will choose Random Forest for our model Predictions as it meets all the expectations for a regression model and gives better performing metric

* Random Forest has a higher R2 for Test data as compared to the other models.
* Random Forest again has a lower RMSE for both the Training and Test data as compared to the other models.
* We can therefore conclude that Random Forest is the best model to use for prediction of 3 hourly load shortfall in Spain

<a id="seven"></a>
## 7. Model Explanations
<a class="anchor" id="1.1"></a>
<a href=#cont>Back to Table of Contents</a>

---
    
| ⚡ Description: Model explanation ⚡ |
| :--------------------------- |
| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |

---

* Coefficient of determination (R2) measures the amount of variance in the predictions explained by the dataset. 
* It is the difference between the samples in the dataset and the predictions made by the model.
* It is measure from zero to one with one representing a perfect model and zero showing that the model will perform badly on unseen data.
* RMSE is the square root of the mean square error (MSE) which represents the average of the squared difference between the true and predicted values. 
* It measures the variance of the residuals, while the RMSE measures the standard deviation of the residuals.
* The smaller the RMSE of the model the better.

### Choosen method's logic:

* Initially we started building our model using linear regression.
* However a linear model is not appropriate for data that is not linear, it also suffers from multi-colinearity.
* Ridge regression shrinks the coefficients and it helps to reduce the model complexity and multi-collinearity.
* Lasso regression helps in reducing overfitting but and in feature selection by setting coefficients with high values to zero.
* Decision trees are not affected by multicolinearity, they support non-linearity and are resistant to outliers further more they require little data preprocessing.
* However Decision trees are prone to overfitting and parameter tuning can led to biased learned trees if some classes dominate.
* Random forests address the problem of overfitting.
* They use ensemble learning methods for regression by constructing several Decision trees during training and outputs the mean of the classes as the prediction of all the trees.

## Conclusion

* As aspiring data scientists we have developed a model that will assist in predicting the 3 hourly load shortfall of power generated by renewable sources in Spain .
* This will assist in informing the Spanish Government of any trends and patterns of the country's renewable resources and fossil fuel energy generation and whether it is viable to expand its' renewable energy resource infrastructure investments.

## Working on Predicting Load_shortfall_3h
"""

test_data.head()

#Engineering New Features ( i.e Desampling the Time) that will help us in our modeling

test_data['Year']  = test_data['time'].astype('datetime64').dt.year
test_data['Month_of_year']  = test_data['time'].astype('datetime64').dt.month
test_data['Week_of_year'] = test_data['time'].astype('datetime64').dt.weekofyear
test_data['Day_of_year']  = test_data['time'].astype('datetime64').dt.dayofyear
test_data['Day_of_month']  = test_data['time'].astype('datetime64').dt.day
test_data['Day_of_week'] = test_data['time'].astype('datetime64').dt.dayofweek
test_data['Hour_of_week'] = ((test_data['time'].astype('datetime64').dt.dayofweek) * 24 + 24) - (24 - test_data['time'].astype('datetime64').dt.hour)
test_data['Hour_of_day']  = test_data['time'].astype('datetime64').dt.hour

time = test_data['time']

#Filling missing values
test_data['Valencia_pressure'].fillna(test_data['Valencia_pressure'].mean(), inplace = True)

test_data = test_data[['Madrid_wind_speed', 'Valencia_wind_deg', 'Bilbao_rain_1h',
       'Valencia_wind_speed', 'Seville_humidity', 'Madrid_humidity',
       'Bilbao_clouds_all', 'Bilbao_wind_speed', 'Seville_clouds_all',
       'Bilbao_wind_deg', 'Barcelona_wind_speed', 'Barcelona_wind_deg',
       'Madrid_clouds_all', 'Seville_wind_speed', 'Barcelona_rain_1h',
       'Seville_pressure', 'Seville_rain_1h', 'Bilbao_snow_3h',
       'Barcelona_pressure', 'Seville_rain_3h', 'Madrid_rain_1h',
       'Barcelona_rain_3h', 'Valencia_snow_3h', 'Madrid_weather_id',
       'Barcelona_weather_id', 'Bilbao_pressure', 'Seville_weather_id',
       'Valencia_pressure', 'Seville_temp_max', 'Bilbao_weather_id', 
        'Valencia_humidity', 'Year', 'Month_of_year', 'Day_of_month', 'Day_of_week', 'Hour_of_day']]

#Transforming Valencia_wind_deg to numeric
test_data['Valencia_wind_deg'] = test_data['Valencia_wind_deg'].str.extract('(\d+)').astype('int64')
test_data['Seville_pressure'] = test_data['Seville_pressure'].str.extract('(\d+)').astype('int64')

test_data['load_shortfall_3h'] = RF.predict(test_data)

test_data['time'] = time
load = test_data[['time','load_shortfall_3h']]
load.to_csv('sample_submission_load_shortfall.csv', index = False)
load